{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Iris DataSet</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    The Iris DataSet is a classical dataset that was introduced by the British statistician Ronald Fisher. He collected 50 different samples for each of the 3 Iris flower species. For each sample, he included the length and width of the speals and the petals, along with the name of the species it belongs to. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will try to implement a classifier that would predict the species of an Iris plant given the 4 features like in the dataset.<br>\n",
    "We will mainly try two algorithms for the classifier, the linearSVM and SVM, and we will try out different paramaters for these models using the greadSearch method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Loading the dataset</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's load the Iris dataset from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the iris dataset and its corresponding data and targets\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Store the dataset in a variable\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into the variable x\n",
    "X = iris.data\n",
    "\n",
    "# Load the target into the variable y\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we split the data into two sets, one for training and one for testing for later use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "\n",
    "\n",
    "# use train/test split with different random_state values \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=None, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Learning data using LinearSVC Model </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Choosing paramaters using grid search</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We are going to brute force the hyperparamaters of the LinearSVC model using the gridSearch class<br>First, we need to choose the set of hyper-paramaters for the grid to bruteforce upon<br>Then, we pass these paramters along with the model type to the grid class.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# choose possible paramaters\n",
    "param_grid = {\n",
    "               \n",
    "    'C':[1,10,100,300,500,700,1000],\n",
    "    'tol':[1e-4,1e-5,1e-6]\n",
    "}\n",
    "\n",
    "# instantiate the grid\n",
    "# the cv param indicates the number of folds and the scoring param indicates the scoring stratetgy\n",
    "grid = GridSearchCV(LinearSVC(random_state=2), param_grid, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we let the gridSearchCV instance search for the best combination of hyperparamaters by training on the training set that we have split from the main data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=2, tol=0.0001,\n",
       "     verbose=0),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [1, 10, 100, 300, 500, 700, 1000], 'tol': [0.0001, 1e-05, 1e-06]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the grid with data\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see the best paramaters the gridSearch has found for us and the respective model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best paramaters :  {'C': 10, 'tol': 0.0001}\n",
      "best score :  0.95\n"
     ]
    }
   ],
   "source": [
    "# print the best hyper-paramaters\n",
    "print(\"best paramaters : \" ,grid.best_params_)\n",
    "print(\"best score : \",grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93333333333333335"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = grid.best_estimator_\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the LinearSVC model has yeilded an accuracy rate of 93.3% on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Learning data using SVC Model</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now we will try and see whether the SVC model would lead to better results</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We will repeat the whole process, and the only difference is the hyperparamaters given to the gridSearch instance.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'kernel': ['rbf'], 'gamma': [0.001, 0.0001, 1e-05], 'C': [1, 10, 100, 500, 1000]}, {'kernel': ['linear'], 'C': [1, 10, 100, 500, 1000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# choose possible paramaters using different kernels\n",
    "param_grid = [\n",
    "    {\n",
    "        'kernel': ['rbf'],\n",
    "        'gamma': [1e-3, 1e-4,1e-5],\n",
    "        'C': [1, 10, 100,500, 1000]\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['linear'], \n",
    "        'C': [1, 10, 100,500, 1000]\n",
    "    }\n",
    "]\n",
    "\n",
    "# instantiate the grid\n",
    "# the cv param indicates the number of folds and the scoring param indicates the scoring stratetgy\n",
    "grid = GridSearchCV(SVC(random_state=0), param_grid, cv=10, scoring='accuracy')\n",
    "\n",
    "\n",
    "# fit the grid with data\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best paramaters :  {'C': 500, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "best score :  0.983333333333\n"
     ]
    }
   ],
   "source": [
    "# print the best hyper-paramaters\n",
    "print(\"best paramaters : \" ,grid.best_params_)\n",
    "print(\"best score : \",grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96666666666666667"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = grid.best_estimator_\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The SVC model has scored a rate of 96.7% accuracy on the same test set that the linearSVC model has been tested on, therefore we conclude that the linearSVC model might be a better option in tackling this problem</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
