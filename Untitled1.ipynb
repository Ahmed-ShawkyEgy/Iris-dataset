{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Iris DataSet</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Loading the dataset</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Load the iris dataset and its corresponding data and targets</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into the variable x\n",
    "X = iris.data\n",
    "\n",
    "# Load the target into the variable y\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split the data into two sets, one for training and one for testing for later use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "\n",
    "\n",
    "# use train/test split with different random_state values \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=4, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Learning data using LinearSVC Model </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Choosing paramaters using grid search</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We are going to brute force the hyperparamaters of the LinearSVC model using the gridSearch class<br>First, we need to choose the set of hyper-paramaters for the grid to bruteforce upon<br>Then, we pass these paramters along with the model type to the grid class.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [1, 10, 100, 300, 500, 700, 1000], 'tol': [0.0001, 1e-05, 1e-06]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# choose possible paramaters\n",
    "param_grid = {\n",
    "               \n",
    "    'C':[1,10,100,300,500,700,1000],\n",
    "    'tol':[1e-4,1e-5,1e-6]\n",
    "}\n",
    "\n",
    "# instantiate the grid\n",
    "# the cv param indicates the number of folds and the scoring param indicates the scoring stratetgy\n",
    "grid = GridSearchCV(LinearSVC(random_state=1), param_grid, cv=5, scoring='accuracy', return_train_score=True)\n",
    "\n",
    "\n",
    "# fit the grid with data\n",
    "# note that we don't need to do any splitting since the gridSearch does that for us\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Next, we print out the results</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_score: [ 0.95        0.95        0.95        0.91666667  0.93333333  0.95833333\n",
      "  0.89166667  0.925       0.9         0.86666667  0.88333333  0.9\n",
      "  0.90833333  0.90833333  0.90833333  0.90833333  0.88333333  0.90833333\n",
      "  0.85        0.86666667  0.875     ] \n",
      "\n",
      "std_test_score: [ 0.03153934  0.03153934  0.03153934  0.03690365  0.05028465  0.02754304\n",
      "  0.07365654  0.04100395  0.09224545  0.10056931  0.08697573  0.07051944\n",
      "  0.04729566  0.04729566  0.04573786  0.06142566  0.07322486  0.03224764\n",
      "  0.08949426  0.06830015  0.08262911] \n",
      "\n",
      "mean_train_score: [ 0.96453409  0.96663935  0.96663935  0.93123789  0.94597739  0.97078543\n",
      "  0.91007607  0.93132205  0.93950768  0.8584205   0.92683402  0.94769198\n",
      "  0.88754161  0.92303653  0.9268761   0.94792873  0.90578006  0.91287719\n",
      "  0.87256935  0.88941278  0.87773085] \n",
      "\n",
      "std_train_score: [ 0.00542997  0.00797366  0.00797366  0.04828709  0.03519184  0.00798581\n",
      "  0.07414645  0.04228976  0.0342873   0.08381587  0.05387999  0.03214314\n",
      "  0.05315919  0.05143275  0.03673324  0.01475486  0.05067299  0.06907629\n",
      "  0.07451156  0.05418786  0.06274189]\n"
     ]
    }
   ],
   "source": [
    "# print the mean scores of the 12 different combinations of hyperparamaters over 10 folds\n",
    "\n",
    "print(\"mean_test_score:\",grid.cv_results_['mean_test_score'],'\\n')\n",
    "print(\"std_test_score:\",grid.cv_results_['std_test_score'],'\\n')\n",
    "print(\"mean_train_score:\",grid.cv_results_['mean_train_score'],'\\n')\n",
    "print(\"std_train_score:\",grid.cv_results_['std_train_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Then we show the best hyper-paramaters for our model along with the best scores </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best paramaters :  {'C': 10, 'tol': 1e-06}\n",
      "best score :  0.958333333333\n"
     ]
    }
   ],
   "source": [
    "# print the best hyper-paramaters\n",
    "print(\"best paramaters : \" ,grid.best_params_)\n",
    "print(\"best score : \",grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = grid.best_estimator_\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>So the LinearSVC model has yeilded an accuracy rate of 100% on the test set, which is the best we could hope for</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Learning data using SVC Model</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now we will try and see whether the SVC model would lead to better results</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We will repeat the whole process, and the only difference is the hyperparamaters given to the gridSearch instance.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=1, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'kernel': ['rbf'], 'gamma': [0.001, 0.0001], 'C': [1, 10, 100, 500, 1000]}, {'kernel': ['linear'], 'C': [1, 10, 100, 500, 1000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# choose possible paramaters\n",
    "param_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100,500, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100,500, 1000]}]\n",
    "\n",
    "# instantiate the grid\n",
    "# the cv param indicates the number of folds and the scoring param indicates the scoring stratetgy\n",
    "grid = GridSearchCV(SVC(random_state=1), param_grid, cv=10, scoring='accuracy', return_train_score=True)\n",
    "\n",
    "\n",
    "# fit the grid with data\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best paramaters :  {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "best score :  0.983333333333\n"
     ]
    }
   ],
   "source": [
    "# print the best hyper-paramaters\n",
    "print(\"best paramaters : \" ,grid.best_params_)\n",
    "print(\"best score : \",grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96666666666666667"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = grid.best_estimator_\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The SVC model has scored a rate of 96.7% accuracy on the same test set that the linearSVC model has been tested on, therefore we conclude that the linearSVC model might be a better option in tackling this problem</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
